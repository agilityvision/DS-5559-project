{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Features and Building Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is for my (Eric) Spark setup, you don't need to run this\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, asc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType, DoubleType, DateType\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = spark.read.csv('df_house.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up some titles\n",
    "df_house = df_house.withColumnRenamed('candidatevotes', 'CAND_VOTES')\n",
    "df_house = df_house.withColumnRenamed('totalvotes', 'TOTAL_VOTES')\n",
    "df_house = df_house.withColumnRenamed('VOTE_percent', 'PERCENT_VOTES')\n",
    "\n",
    "#drop index that is brought in\n",
    "df_house = df_house.drop(col('_c0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CAND_ID: string (nullable = true)\n",
      " |-- CAND_NAME: string (nullable = true)\n",
      " |-- CAND_PTY_AFFILIATION: string (nullable = true)\n",
      " |-- CAND_ELECTION_YR: integer (nullable = true)\n",
      " |-- CAND_OFFICE_ST: string (nullable = true)\n",
      " |-- CAND_OFFICE: string (nullable = true)\n",
      " |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n",
      " |-- CAND_ICI: string (nullable = true)\n",
      " |-- CAND_STATUS: string (nullable = true)\n",
      " |-- CAND_PCC: string (nullable = true)\n",
      " |-- CAND_CITY: string (nullable = true)\n",
      " |-- CAND_ST: string (nullable = true)\n",
      " |-- CAND_ZIP: double (nullable = true)\n",
      " |-- CAND_VOTES: integer (nullable = true)\n",
      " |-- TOTAL_VOTES: integer (nullable = true)\n",
      " |-- PERCENT_VOTES: double (nullable = true)\n",
      " |-- WINNER: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "source": [
    "## Add Inbumbent feature column as 1/0"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+-----+\n|CAND_ICI|count|\n+--------+-----+\n|    null|    3|\n|       O|  168|\n|       C|  528|\n|       I|  481|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_house.groupBy('CAND_ICI').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+-----+\n|CAND_ICU|count|\n+--------+-----+\n|     0.0|  858|\n|     1.0|  692|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_house = df_house.withColumn('CAND_ICU', F.when(col('CAND_ICI') == 'I', 1.0).otherwise(0.0))\n",
    "df_house.groupBy('CAND_ICU').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 2016, 2018 to add in features as they are year dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house.filter(df_house.CAND_ELECTION_YR == 2016)\n",
    "df_house18 = df_house.filter(df_house.CAND_ELECTION_YR == 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2016\n",
    "avgsum_donation_16 = spark.read.csv('./features/avgsum_donation-16.csv', inferSchema=True, header=True)\n",
    "num_big_donations_16 = spark.read.csv('./features/num_big_donations-16.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_16 = spark.read.csv('./features/num_out_of_state_donations-16.csv', inferSchema=True, header=True)\n",
    "numdonations16 = spark.read.csv('./features/numdonations16.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2018\n",
    "avgsum_donation_18 = spark.read.csv('./features/avgsum_donation-18.csv', inferSchema=True, header=True)\n",
    "num_big_donations_18 = spark.read.csv('./features/num_big_donations-18.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_18 = spark.read.csv('./features/num_out_of_state_donations-18.csv', inferSchema=True, header=True)\n",
    "numdonations18 = spark.read.csv('./features/numdonations18.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "source": [
    "### 2020:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2020\n",
    "avgsum_donation_20 = spark.read.csv('./features/avgsum_donation-20.csv', inferSchema=True, header=True)\n",
    "num_big_donations_20 = spark.read.csv('./features/num_big_donations-20.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_20 = spark.read.csv('./features/num_out_of_state_donations-20.csv', inferSchema=True, header=True)\n",
    "numdonations20 = spark.read.csv('./features/numdonations20.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Candidates to Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house16.join(avgsum_donation_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house16 = df_house16.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_big_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_out_of_state_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(numdonations16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house16 = df_house16.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house16 = df_house16.filter(col('TOTAL_DONATIONS').isNotNull())\n",
    "\n",
    "#simpler filters\n",
    "df_house16 = df_house16.withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT')))\n",
    "\n",
    "#identify races that only have information by CONCAT value\n",
    "single_cand16 = df_house16.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .count() \\\n",
    "                          .filter('count == 1') \\\n",
    "                          .select('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT'))) \\\n",
    "                          .select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#create list of \n",
    "all_cand16 = df_house16.select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#identifies from all races only those not single\n",
    "multi_cand16 = [x for x in all_cand16 if x not in single_cand16]\n",
    "\n",
    "#filter candidate pool to final form\n",
    "df_house16 = df_house16.filter(col('CONCAT').isin(multi_cand16))\n",
    "\n",
    "\n",
    "#calculate totals for various metrics\n",
    "agg_total_donations16 = df_house16.groupBy('CONCAT').agg({'TOTAL_DONATIONS':'sum'}).withColumnRenamed('sum(TOTAL_DONATIONS)','AGG_TOTAL_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_total_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_big_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_BIG_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_BIG_DONATIONS)','AGG_NUMBER_BIG_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_big_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_out_of_state_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_OUT_OF_STATE_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OUT_OF_STATE_DONATIONS)','AGG_NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_out_of_state_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_of_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_OF_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OF_DONATIONS)','AGG_NUMBER_OF_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_of_donations16, on='CONCAT', how='left')\n",
    "\n",
    "\n",
    "#relative calculations between candidates for a given race\n",
    "df_house16 = df_house16.withColumn('REL_TOTAL_DONATIONS', col('TOTAL_DONATIONS')/col('AGG_TOTAL_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('AGG_NUMBER_BIG_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('AGG_NUMBER_OUT_OF_STATE_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('PERCENT_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('NUMBER_OF_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('PERCENT_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('NUMBER_OF_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_OF_DONATIONS', col('NUMBER_OF_DONATIONS')/col('AGG_NUMBER_OF_DONATIONS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "df_house16.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house18 = df_house18.join(avgsum_donation_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house18 = df_house18.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_big_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_out_of_state_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(numdonations18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house18 = df_house18.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house18 = df_house18.filter(col('TOTAL_DONATIONS').isNotNull())\n",
    "\n",
    "#simpler filters\n",
    "df_house18 = df_house18.withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT')))\n",
    "\n",
    "###\n",
    "\n",
    "#identify races that only have information by CONCAT value\n",
    "single_cand18 = df_house18.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .count() \\\n",
    "                          .filter('count == 1') \\\n",
    "                          .select('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT'))) \\\n",
    "                          .select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#create list of all candidate races\n",
    "all_cand18 = df_house18.select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#identifies from all races only those not single\n",
    "multi_cand18 = [x for x in all_cand18 if x not in single_cand18]\n",
    "\n",
    "#filter candidate pool to final form\n",
    "df_house18 = df_house18.filter(col('CONCAT').isin(multi_cand18))\n",
    "\n",
    "###\n",
    "\n",
    "#calculate totals for various metrics\n",
    "agg_total_donations18 = df_house18.groupBy('CONCAT').agg({'TOTAL_DONATIONS':'sum'}).withColumnRenamed('sum(TOTAL_DONATIONS)','AGG_TOTAL_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_total_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_big_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_BIG_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_BIG_DONATIONS)','AGG_NUMBER_BIG_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_big_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_out_of_state_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_OUT_OF_STATE_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OUT_OF_STATE_DONATIONS)','AGG_NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_out_of_state_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_of_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_OF_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OF_DONATIONS)','AGG_NUMBER_OF_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_of_donations18, on='CONCAT', how='left')\n",
    "\n",
    "\n",
    "#relative calculations between candidates for a given race\n",
    "df_house18 = df_house18.withColumn('REL_TOTAL_DONATIONS', col('TOTAL_DONATIONS')/col('AGG_TOTAL_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('AGG_NUMBER_BIG_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('AGG_NUMBER_OUT_OF_STATE_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('PERCENT_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('NUMBER_OF_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('PERCENT_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('NUMBER_OF_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_OF_DONATIONS', col('NUMBER_OF_DONATIONS')/col('AGG_NUMBER_OF_DONATIONS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house18.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine 2016 and 2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = reduce(DataFrame.unionAll, [df_house16, df_house18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- CONCAT: string (nullable = true)\n |-- CAND_ID: string (nullable = true)\n |-- CAND_NAME: string (nullable = true)\n |-- CAND_PTY_AFFILIATION: string (nullable = true)\n |-- CAND_ELECTION_YR: integer (nullable = true)\n |-- CAND_OFFICE_ST: string (nullable = true)\n |-- CAND_OFFICE: string (nullable = true)\n |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n |-- CAND_ICI: string (nullable = true)\n |-- CAND_STATUS: string (nullable = true)\n |-- CAND_PCC: string (nullable = true)\n |-- CAND_CITY: string (nullable = true)\n |-- CAND_ST: string (nullable = true)\n |-- CAND_ZIP: double (nullable = true)\n |-- CAND_VOTES: integer (nullable = true)\n |-- TOTAL_VOTES: integer (nullable = true)\n |-- PERCENT_VOTES: double (nullable = true)\n |-- WINNER: integer (nullable = true)\n |-- AVERAGE_DONATION: double (nullable = true)\n |-- TOTAL_DONATIONS: double (nullable = true)\n |-- NUMBER_BIG_DONATIONS: integer (nullable = false)\n |-- NUMBER_OUT_OF_STATE_DONATIONS: integer (nullable = false)\n |-- NUMBER_OF_DONATIONS: integer (nullable = true)\n |-- AGG_TOTAL_DONATIONS: double (nullable = true)\n |-- AGG_NUMBER_BIG_DONATIONS: long (nullable = true)\n |-- AGG_NUMBER_OUT_OF_STATE_DONATIONS: long (nullable = true)\n |-- AGG_NUMBER_OF_DONATIONS: long (nullable = true)\n |-- REL_TOTAL_DONATIONS: double (nullable = true)\n |-- REL_NUMBER_BIG_DONATIONS: double (nullable = true)\n |-- REL_NUMBER_OUT_OF_STATE_DONATIONS: double (nullable = true)\n |-- PERCENT_BIG_DONATIONS: double (nullable = true)\n |-- PERCENT_OUT_OF_STATE_DONATIONS: double (nullable = true)\n |-- REL_NUMBER_OF_DONATIONS: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "training_fraction = [0.8, 0.2]\n",
    "ITERS = 10\n",
    "target = 'WINNER'\n",
    "vars_to_keep = ['PERCENT_BIG_DONATIONS', 'PERCENT_OUT_OF_STATE_DONATIONS', 'CAND_ICU']\n",
    "#vars_to_keep = ['REL_TOTAL_DONATIONS','REL_NUMBER_OF_DONATIONS','REL_NUMBER_BIG_DONATIONS','REL_NUMBER_OUT_OF_STATE_DONATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_house.select([target]+vars_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|WINNER|count|\n+------+-----+\n|     1|  560|\n|     0|  620|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "df_model.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+---------------------+------------------------------+--------+\n|WINNER|PERCENT_BIG_DONATIONS|PERCENT_OUT_OF_STATE_DONATIONS|CAND_ICU|\n+------+---------------------+------------------------------+--------+\n|     1|   0.5947368421052631|           0.18947368421052632|     1.0|\n|     0|                  0.5|                           0.5|     0.0|\n|     0|                  1.0|                           0.0|     0.0|\n|     1|   0.4584527220630373|           0.10601719197707736|     0.0|\n|     0|   0.4835164835164835|          0.054945054945054944|     0.0|\n|     0|   0.5692934782608695|           0.23505434782608695|     0.0|\n|     1|  0.06684602649006623|           0.26076158940397354|     1.0|\n|     1|    0.514018691588785|            0.2616822429906542|     1.0|\n|     0|  0.47058823529411764|                           0.0|     0.0|\n|     0|                  0.5|                           0.0|     0.0|\n+------+---------------------+------------------------------+--------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "df_model.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Individual Feature, building model and ranking AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM ASSIGNMENT 7 ##\n",
    "\n",
    "def compute_univariate_aucs(df, target, training_fraction, iters, seed):\n",
    "\n",
    "    # split the data into train/test using seed\n",
    "    data_train, data_test = df.randomSplit(training_fraction,seed=seed)\n",
    "    \n",
    "    # list of predictor variables\n",
    "    vars = df.columns[1:]\n",
    "    \n",
    "    # results storage\n",
    "    df_auc = pd.DataFrame(index=vars, columns=['weight','auroc'])    \n",
    "\n",
    "    for v in vars:    \n",
    "        print('=== analysis of variable: {}'.format(v))\n",
    "\n",
    "        # create train and test dataframes with columns: target, v\n",
    "        datai_tr = data_train.select(target,v)\n",
    "        datai_te = data_test.select(target,v)\n",
    "\n",
    "        # cast to LabeledPoint\n",
    "        # train\n",
    "        datai_tr_lp = datai_tr \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "        \n",
    "        # test\n",
    "        datai_te_lp = datai_te \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "\n",
    "        # train logistic regression, setting iterations, including intercept\n",
    "        LR_Model = LogisticRegressionWithLBFGS.train(datai_tr_lp, iterations=iters, intercept=False)\n",
    "\n",
    "        # from test set, zip labels with predicted labels and cast to float\n",
    "        #p.label    # gives label\n",
    "        #p.features # gives features\n",
    "        \n",
    "        act_pred_test_set = datai_te_lp.map(lambda p: (p.label, LR_Model.predict(p.features))) \\\n",
    "                                            .map(lambda row: (row[0], row[1] * 1.0))\n",
    "        \n",
    "        metrics = BinaryClassificationMetrics(act_pred_test_set)\n",
    "        # metrics.areaUnderROC\n",
    "        \n",
    "        df_auc['weight'].loc[v] = LR_Model.weights  # store the weights\n",
    "        df_auc['auroc'].loc[v] = metrics.areaUnderROC # extract AUROC\n",
    "        print('=== completed analysis of variable: {}'.format(v))\n",
    "        \n",
    "    df_auc.sort_values(by='auroc', ascending=False, inplace=True)\n",
    "    \n",
    "    return df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== analysis of variable: PERCENT_BIG_DONATIONS\n",
      "=== completed analysis of variable: PERCENT_BIG_DONATIONS\n",
      "=== analysis of variable: PERCENT_OUT_OF_STATE_DONATIONS\n",
      "=== completed analysis of variable: PERCENT_OUT_OF_STATE_DONATIONS\n",
      "=== analysis of variable: CAND_ICU\n",
      "=== completed analysis of variable: CAND_ICU\n"
     ]
    }
   ],
   "source": [
    "df_output = compute_univariate_aucs(df_model, target, training_fraction, ITERS, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               weight     auroc\n",
       "CAND_ICU                           [2.73379752410494]  0.894401\n",
       "PERCENT_OUT_OF_STATE_DONATIONS  [0.41643476016989817]  0.774775\n",
       "PERCENT_BIG_DONATIONS             [0.357086452369367]  0.754167"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>weight</th>\n      <th>auroc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>CAND_ICU</th>\n      <td>[2.73379752410494]</td>\n      <td>0.894401</td>\n    </tr>\n    <tr>\n      <th>PERCENT_OUT_OF_STATE_DONATIONS</th>\n      <td>[0.41643476016989817]</td>\n      <td>0.774775</td>\n    </tr>\n    <tr>\n      <th>PERCENT_BIG_DONATIONS</th>\n      <td>[0.357086452369367]</td>\n      <td>0.754167</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('env': venv)",
   "display_name": "Python 3.7.9 64-bit ('env': venv)",
   "metadata": {
    "interpreter": {
     "hash": "b010baa8ada5fd52dd9d23d6d3c38bbd112ecbd3a5dedcf3dc96d86e3e34914a"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}