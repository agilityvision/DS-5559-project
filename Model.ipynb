{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Features and Building Predictive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, asc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType, DoubleType, DateType\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = spark.read.csv('df_house.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up some titles\n",
    "df_house = df_house.withColumnRenamed('candidatevotes', 'CAND_VOTES')\n",
    "df_house = df_house.withColumnRenamed('totalvotes', 'TOTAL_VOTES')\n",
    "df_house = df_house.withColumnRenamed('VOTE_percent', 'PERCENT_VOTES')\n",
    "\n",
    "#drop index that is brought in\n",
    "df_house = df_house.drop(col('_c0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CAND_ID: string (nullable = true)\n",
      " |-- CAND_NAME: string (nullable = true)\n",
      " |-- CAND_PTY_AFFILIATION: string (nullable = true)\n",
      " |-- CAND_ELECTION_YR: integer (nullable = true)\n",
      " |-- CAND_OFFICE_ST: string (nullable = true)\n",
      " |-- CAND_OFFICE: string (nullable = true)\n",
      " |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n",
      " |-- CAND_ICI: string (nullable = true)\n",
      " |-- CAND_STATUS: string (nullable = true)\n",
      " |-- CAND_PCC: string (nullable = true)\n",
      " |-- CAND_CITY: string (nullable = true)\n",
      " |-- CAND_ST: string (nullable = true)\n",
      " |-- CAND_ZIP: double (nullable = true)\n",
      " |-- CAND_VOTES: integer (nullable = true)\n",
      " |-- TOTAL_VOTES: integer (nullable = true)\n",
      " |-- PERCENT_VOTES: double (nullable = true)\n",
      " |-- WINNER: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 2016, 2018 to add in features as they are year dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house.filter(df_house.CAND_ELECTION_YR == 2016)\n",
    "df_house18 = df_house.filter(df_house.CAND_ELECTION_YR == 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2016\n",
    "avgsum_donation_16 = spark.read.csv('./features/avgsum_donation-16.csv', inferSchema=True, header=True)\n",
    "num_big_donations_16 = spark.read.csv('./features/num_big_donations-16.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_16 = spark.read.csv('./features/num_out_of_state_donations-16.csv', inferSchema=True, header=True)\n",
    "numdonations16 = spark.read.csv('./features/numdonations16.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2018\n",
    "avgsum_donation_18 = spark.read.csv('./features/avgsum_donation-18.csv', inferSchema=True, header=True)\n",
    "num_big_donations_18 = spark.read.csv('./features/num_big_donations-18.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_18 = spark.read.csv('./features/num_out_of_state_donations-18.csv', inferSchema=True, header=True)\n",
    "numdonations18 = spark.read.csv('./features/numdonations18.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Candidates to Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house16.join(avgsum_donation_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house16 = df_house16.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_big_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_out_of_state_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(numdonations16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house16 = df_house16.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house16 = df_house16.filter(col('TOTAL_DONATIONS').isNotNull())\n",
    "\n",
    "#simpler filters\n",
    "df_house16 = df_house16.withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT')))\n",
    "\n",
    "#identify races that only have information by CONCAT value\n",
    "single_cand16 = df_house16.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .count() \\\n",
    "                          .filter('count == 1') \\\n",
    "                          .select('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT'))) \\\n",
    "                          .select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#create list of \n",
    "all_cand16 = df_house16.select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#identifies from all races only those not single\n",
    "multi_cand16 = [x for x in all_cand16 if x not in single_cand16]\n",
    "\n",
    "#filter candidate pool to final form\n",
    "df_house16 = df_house16.filter(col('CONCAT').isin(multi_cand16))\n",
    "\n",
    "\n",
    "#calculate totals for various metrics\n",
    "agg_total_donations16 = df_house16.groupBy('CONCAT').agg({'TOTAL_DONATIONS':'sum'}).withColumnRenamed('sum(TOTAL_DONATIONS)','AGG_TOTAL_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_total_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_big_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_BIG_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_BIG_DONATIONS)','AGG_NUMBER_BIG_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_big_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_out_of_state_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_OUT_OF_STATE_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OUT_OF_STATE_DONATIONS)','AGG_NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_out_of_state_donations16, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_of_donations16 = df_house16.groupBy('CONCAT').agg({'NUMBER_OF_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OF_DONATIONS)','AGG_NUMBER_OF_DONATIONS')\n",
    "df_house16 = df_house16.join(agg_number_of_donations16, on='CONCAT', how='left')\n",
    "\n",
    "\n",
    "#relative calculations between candidates for a given race\n",
    "df_house16 = df_house16.withColumn('REL_TOTAL_DONATIONS', col('TOTAL_DONATIONS')/col('AGG_TOTAL_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('AGG_NUMBER_BIG_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('AGG_NUMBER_OUT_OF_STATE_DONATIONS'))\n",
    "df_house16 = df_house16.withColumn('REL_NUMBER_OF_DONATIONS', col('NUMBER_OF_DONATIONS')/col('AGG_NUMBER_OF_DONATIONS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house16.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house18 = df_house18.join(avgsum_donation_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house18 = df_house18.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_big_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_out_of_state_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(numdonations18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house18 = df_house18.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house18 = df_house18.filter(col('TOTAL_DONATIONS').isNotNull())\n",
    "\n",
    "#simpler filters\n",
    "df_house18 = df_house18.withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT')))\n",
    "\n",
    "###\n",
    "\n",
    "#identify races that only have information by CONCAT value\n",
    "single_cand18 = df_house18.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .count() \\\n",
    "                          .filter('count == 1') \\\n",
    "                          .select('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT') \\\n",
    "                          .withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT'))) \\\n",
    "                          .select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#create list of all candidate races\n",
    "all_cand18 = df_house18.select('CONCAT').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "#identifies from all races only those not single\n",
    "multi_cand18 = [x for x in all_cand18 if x not in single_cand18]\n",
    "\n",
    "#filter candidate pool to final form\n",
    "df_house18 = df_house18.filter(col('CONCAT').isin(multi_cand18))\n",
    "\n",
    "###\n",
    "\n",
    "#calculate totals for various metrics\n",
    "agg_total_donations18 = df_house18.groupBy('CONCAT').agg({'TOTAL_DONATIONS':'sum'}).withColumnRenamed('sum(TOTAL_DONATIONS)','AGG_TOTAL_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_total_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_big_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_BIG_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_BIG_DONATIONS)','AGG_NUMBER_BIG_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_big_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_out_of_state_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_OUT_OF_STATE_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OUT_OF_STATE_DONATIONS)','AGG_NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_out_of_state_donations18, on='CONCAT', how='left')\n",
    "\n",
    "agg_number_of_donations18 = df_house18.groupBy('CONCAT').agg({'NUMBER_OF_DONATIONS':'sum'}).withColumnRenamed('sum(NUMBER_OF_DONATIONS)','AGG_NUMBER_OF_DONATIONS')\n",
    "df_house18 = df_house18.join(agg_number_of_donations18, on='CONCAT', how='left')\n",
    "\n",
    "\n",
    "#relative calculations between candidates for a given race\n",
    "df_house18 = df_house18.withColumn('REL_TOTAL_DONATIONS', col('TOTAL_DONATIONS')/col('AGG_TOTAL_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_BIG_DONATIONS', col('NUMBER_BIG_DONATIONS')/col('AGG_NUMBER_BIG_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_OUT_OF_STATE_DONATIONS', col('NUMBER_OUT_OF_STATE_DONATIONS')/col('AGG_NUMBER_OUT_OF_STATE_DONATIONS'))\n",
    "df_house18 = df_house18.withColumn('REL_NUMBER_OF_DONATIONS', col('NUMBER_OF_DONATIONS')/col('AGG_NUMBER_OF_DONATIONS'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house18.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine 2016 and 2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = reduce(DataFrame.unionAll, [df_house16, df_house18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CONCAT: string (nullable = true)\n",
      " |-- CAND_ID: string (nullable = true)\n",
      " |-- CAND_NAME: string (nullable = true)\n",
      " |-- CAND_PTY_AFFILIATION: string (nullable = true)\n",
      " |-- CAND_ELECTION_YR: integer (nullable = true)\n",
      " |-- CAND_OFFICE_ST: string (nullable = true)\n",
      " |-- CAND_OFFICE: string (nullable = true)\n",
      " |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n",
      " |-- CAND_ICI: string (nullable = true)\n",
      " |-- CAND_STATUS: string (nullable = true)\n",
      " |-- CAND_PCC: string (nullable = true)\n",
      " |-- CAND_CITY: string (nullable = true)\n",
      " |-- CAND_ST: string (nullable = true)\n",
      " |-- CAND_ZIP: double (nullable = true)\n",
      " |-- CAND_VOTES: integer (nullable = true)\n",
      " |-- TOTAL_VOTES: integer (nullable = true)\n",
      " |-- PERCENT_VOTES: double (nullable = true)\n",
      " |-- WINNER: integer (nullable = true)\n",
      " |-- AVERAGE_DONATION: double (nullable = true)\n",
      " |-- TOTAL_DONATIONS: double (nullable = true)\n",
      " |-- NUMBER_BIG_DONATIONS: integer (nullable = false)\n",
      " |-- NUMBER_OUT_OF_STATE_DONATIONS: integer (nullable = false)\n",
      " |-- NUMBER_OF_DONATIONS: integer (nullable = true)\n",
      " |-- AGG_TOTAL_DONATIONS: double (nullable = true)\n",
      " |-- AGG_NUMBER_BIG_DONATIONS: long (nullable = true)\n",
      " |-- AGG_NUMBER_OUT_OF_STATE_DONATIONS: long (nullable = true)\n",
      " |-- AGG_NUMBER_OF_DONATIONS: long (nullable = true)\n",
      " |-- REL_TOTAL_DONATIONS: double (nullable = true)\n",
      " |-- REL_NUMBER_BIG_DONATIONS: double (nullable = true)\n",
      " |-- REL_NUMBER_OUT_OF_STATE_DONATIONS: double (nullable = true)\n",
      " |-- REL_NUMBER_OF_DONATIONS: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "training_fraction = [0.8, 0.2]\n",
    "ITERS = 10\n",
    "target = 'WINNER'\n",
    "vars_to_keep = ['REL_TOTAL_DONATIONS','REL_NUMBER_OF_DONATIONS','REL_NUMBER_BIG_DONATIONS','REL_NUMBER_OUT_OF_STATE_DONATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_house.select([target]+vars_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|WINNER|count|\n",
      "+------+-----+\n",
      "|     1|  560|\n",
      "|     0|  620|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+------------------+-------------------+\n",
      "|WINNER|TOTAL_DONATIONS|  AVERAGE_DONATION|NUMBER_OF_DONATIONS|\n",
      "+------+---------------+------------------+-------------------+\n",
      "|     0|          600.0|             300.0|                  2|\n",
      "|     0|         6300.0|             630.0|                 10|\n",
      "|     1|       606972.0| 688.1768707482993|                882|\n",
      "|     1|       204101.0|1607.0944881889764|                127|\n",
      "|     1|       142575.0|1071.9924812030076|                133|\n",
      "|     0|        26719.0|460.67241379310343|                 58|\n",
      "|     0|        20450.0| 538.1578947368421|                 38|\n",
      "|     1|       104530.0| 901.1206896551724|                116|\n",
      "|     0|         4200.0|             600.0|                  7|\n",
      "|     1|       154000.0|  649.789029535865|                237|\n",
      "+------+---------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Individual Feature, building model and ranking AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM ASSIGNMENT 7 ##\n",
    "\n",
    "def compute_univariate_aucs(df, target, training_fraction, iters, seed):\n",
    "\n",
    "    # split the data into train/test using seed\n",
    "    data_train, data_test = df.randomSplit(training_fraction,seed=seed)\n",
    "    \n",
    "    # list of predictor variables\n",
    "    vars = df.columns[1:]\n",
    "    \n",
    "    # results storage\n",
    "    df_auc = pd.DataFrame(index=vars, columns=['weight','auroc'])    \n",
    "\n",
    "    for v in vars:    \n",
    "        print('=== analysis of variable: {}'.format(v))\n",
    "\n",
    "        # create train and test dataframes with columns: target, v\n",
    "        datai_tr = data_train.select(target,v)\n",
    "        datai_te = data_test.select(target,v)\n",
    "\n",
    "        # cast to LabeledPoint\n",
    "        # train\n",
    "        datai_tr_lp = datai_tr \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "        \n",
    "        # test\n",
    "        datai_te_lp = datai_te \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "\n",
    "        # train logistic regression, setting iterations, including intercept\n",
    "        LR_Model = LogisticRegressionWithLBFGS.train(datai_tr_lp, iterations=iters, intercept=False)\n",
    "\n",
    "        # from test set, zip labels with predicted labels and cast to float\n",
    "        #p.label    # gives label\n",
    "        #p.features # gives features\n",
    "        \n",
    "        act_pred_test_set = datai_te_lp.map(lambda p: (p.label, LR_Model.predict(p.features))) \\\n",
    "                                            .map(lambda row: (row[0], row[1] * 1.0))\n",
    "        \n",
    "        metrics = BinaryClassificationMetrics(act_pred_test_set)\n",
    "        # metrics.areaUnderROC\n",
    "        \n",
    "        df_auc['weight'].loc[v] = LR_Model.weights  # store the weights\n",
    "        df_auc['auroc'].loc[v] = metrics.areaUnderROC # extract AUROC\n",
    "        print('=== completed analysis of variable: {}'.format(v))\n",
    "        \n",
    "    df_auc.sort_values(by='auroc', ascending=False, inplace=True)\n",
    "    \n",
    "    return df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== analysis of variable: TOTAL_DONATIONS\n",
      "=== completed analysis of variable: TOTAL_DONATIONS\n",
      "=== analysis of variable: AVERAGE_DONATION\n",
      "=== completed analysis of variable: AVERAGE_DONATION\n",
      "=== analysis of variable: NUMBER_OF_DONATIONS\n",
      "=== completed analysis of variable: NUMBER_OF_DONATIONS\n"
     ]
    }
   ],
   "source": [
    "df_output = compute_univariate_aucs(df_model, target, training_fraction, ITERS, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL_DONATIONS</th>\n",
       "      <td>[5.095562920049984e-07]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVERAGE_DONATION</th>\n",
       "      <td>[5.146906493825712e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMBER_OF_DONATIONS</th>\n",
       "      <td>[8.923299131147139e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      weight auroc\n",
       "TOTAL_DONATIONS      [5.095562920049984e-07]     1\n",
       "AVERAGE_DONATION     [5.146906493825712e-05]     1\n",
       "NUMBER_OF_DONATIONS  [8.923299131147139e-05]     1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
