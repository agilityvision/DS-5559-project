{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Features and Building Predictive Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Lost 144 candidates to not matching*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, asc\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType, DoubleType, DateType\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark.mllib.regression as reg\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = spark.read.csv('df_house.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up some titles\n",
    "df_house = df_house.withColumnRenamed('candidatevotes', 'CAND_VOTES')\n",
    "df_house = df_house.withColumnRenamed('totalvotes', 'TOTAL_VOTES')\n",
    "df_house = df_house.withColumnRenamed('VOTE_percent', 'PERCENT_VOTES')\n",
    "\n",
    "#drop index that is brought in\n",
    "df_house = df_house.drop(col('_c0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CAND_ID: string (nullable = true)\n",
      " |-- CAND_NAME: string (nullable = true)\n",
      " |-- CAND_PTY_AFFILIATION: string (nullable = true)\n",
      " |-- CAND_ELECTION_YR: integer (nullable = true)\n",
      " |-- CAND_OFFICE_ST: string (nullable = true)\n",
      " |-- CAND_OFFICE: string (nullable = true)\n",
      " |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n",
      " |-- CAND_ICI: string (nullable = true)\n",
      " |-- CAND_STATUS: string (nullable = true)\n",
      " |-- CAND_PCC: string (nullable = true)\n",
      " |-- CAND_CITY: string (nullable = true)\n",
      " |-- CAND_ST: string (nullable = true)\n",
      " |-- CAND_ZIP: double (nullable = true)\n",
      " |-- CAND_VOTES: integer (nullable = true)\n",
      " |-- TOTAL_VOTES: integer (nullable = true)\n",
      " |-- PERCENT_VOTES: double (nullable = true)\n",
      " |-- WINNER: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 2016, 2018 to add in features as they are year dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house.filter(df_house.CAND_ELECTION_YR == 2016)\n",
    "df_house18 = df_house.filter(df_house.CAND_ELECTION_YR == 2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2016\n",
    "avgsum_donation_16 = spark.read.csv('./features/avgsum_donation-16.csv', inferSchema=True, header=True)\n",
    "num_big_donations_16 = spark.read.csv('./features/num_big_donations-16.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_16 = spark.read.csv('./features/num_out_of_state_donations-16.csv', inferSchema=True, header=True)\n",
    "numdonations16 = spark.read.csv('./features/numdonations16.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in features 2018\n",
    "avgsum_donation_18 = spark.read.csv('./features/avgsum_donation-18.csv', inferSchema=True, header=True)\n",
    "num_big_donations_18 = spark.read.csv('./features/num_big_donations-18.csv', inferSchema=True, header=True)\n",
    "num_out_of_state_donations_18 = spark.read.csv('./features/num_out_of_state_donations-18.csv', inferSchema=True, header=True)\n",
    "numdonations18 = spark.read.csv('./features/numdonations18.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join Candidates to Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2016:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16 = df_house16.join(avgsum_donation_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house16 = df_house16.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_big_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(num_out_of_state_donations_16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "df_house16 = df_house16.join(numdonations16, on='CAND_ID', how='left')\n",
    "df_house16 = df_house16.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house16 = df_house16.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house16 = df_house16.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house16 = df_house16.filter(col('TOTAL_DONATIONS').isNotNull())\n",
    "\n",
    "#simpler filters\n",
    "df_house16 = df_house16.withColumn('CONCAT', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO FILTER OUT THE RACES WITH ONLY 1 CANDIDATE\n",
    "# THEN ADJUST THE CALCULATIONS TO BE RELATIVE - going to be very messy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house16.select('CONCAT').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house16.select('CONCAT').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CANNOT GET this filter to work correctly....no idea why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house168 = df_house16.filter(col('CONCAT').isin(c) == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house168.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "646"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house16.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house16.select('CONCAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+--------------------+-----+\n",
      "|CAND_ELECTION_YR|CAND_OFFICE_ST|CAND_OFFICE_DISTRICT|count|\n",
      "+----------------+--------------+--------------------+-----+\n",
      "|            2016|            WA|                 6.0|    2|\n",
      "|            2016|            CA|                16.0|    2|\n",
      "|            2016|            IL|                18.0|    2|\n",
      "|            2016|            NC|                 7.0|    2|\n",
      "|            2016|            CA|                10.0|    2|\n",
      "|            2016|            OR|                 4.0|    2|\n",
      "|            2016|            CO|                 4.0|    2|\n",
      "|            2016|            NY|                13.0|    2|\n",
      "|            2016|            MO|                 2.0|    2|\n",
      "|            2016|            MN|                 3.0|    2|\n",
      "|            2016|            NC|                 6.0|    2|\n",
      "|            2016|            CA|                29.0|    2|\n",
      "|            2016|            VA|                10.0|    2|\n",
      "|            2016|            OH|                 6.0|    2|\n",
      "|            2016|            TX|                13.0|    1|\n",
      "|            2016|            TX|                14.0|    1|\n",
      "|            2016|            OH|                 2.0|    1|\n",
      "|            2016|            MI|                12.0|    3|\n",
      "|            2016|            OH|                15.0|    2|\n",
      "|            2016|            CA|                19.0|    1|\n",
      "+----------------+--------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house16.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "646 originally - 144 that only have 1 candidate = 502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=df_house16.groupBy('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.count().filter(\"count == 1\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.count().filter('count == 1').select('CAND_ELECTION_YR','CAND_OFFICE_ST','CAND_OFFICE_DISTRICT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "b= b.withColumn('Concat', F.concat(col('CAND_ELECTION_YR'),F.lit('_'),col('CAND_OFFICE_ST'),F.lit('_'),col('CAND_OFFICE_DISTRICT'))).select('Concat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c= b.select('Concat').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016_TX_13.0',\n",
       " '2016_TX_14.0',\n",
       " '2016_OH_2.0',\n",
       " '2016_CA_19.0',\n",
       " '2016_NY_12.0',\n",
       " '2016_AZ_6.0',\n",
       " '2016_GA_13.0',\n",
       " '2016_MI_13.0',\n",
       " '2016_PA_2.0',\n",
       " '2016_VA_11.0',\n",
       " '2016_KY_2.0',\n",
       " '2016_OH_3.0',\n",
       " '2016_MS_1.0',\n",
       " '2016_NJ_8.0',\n",
       " '2016_TX_19.0',\n",
       " '2016_TN_8.0',\n",
       " '2016_IL_1.0',\n",
       " '2016_OR_3.0',\n",
       " '2016_TX_4.0',\n",
       " '2016_OK_3.0',\n",
       " '2016_VA_1.0',\n",
       " '2016_TX_11.0',\n",
       " '2016_PA_13.0',\n",
       " '2016_HI_1.0',\n",
       " '2016_CA_5.0',\n",
       " '2016_MO_3.0',\n",
       " '2016_LA_5.0',\n",
       " '2016_MO_6.0',\n",
       " '2016_KY_5.0',\n",
       " '2016_TX_3.0',\n",
       " '2016_GA_8.0',\n",
       " '2016_TX_5.0',\n",
       " '2016_IN_3.0',\n",
       " '2016_TX_26.0',\n",
       " '2016_IL_17.0',\n",
       " '2016_SC_6.0',\n",
       " '2016_OK_1.0',\n",
       " '2016_SC_3.0',\n",
       " '2016_MN_4.0',\n",
       " '2016_CA_35.0',\n",
       " '2016_OH_5.0',\n",
       " '2016_MD_4.0',\n",
       " '2016_GA_6.0',\n",
       " '2016_LA_6.0',\n",
       " '2016_MO_8.0',\n",
       " '2016_NJ_10.0',\n",
       " '2016_GA_14.0',\n",
       " '2016_CA_28.0',\n",
       " '2016_MD_1.0',\n",
       " '2016_MI_2.0',\n",
       " '2016_TN_1.0',\n",
       " '2016_NY_15.0',\n",
       " '2016_GA_7.0',\n",
       " '2016_PA_6.0',\n",
       " '2016_CA_15.0',\n",
       " '2016_TX_12.0',\n",
       " '2016_OK_4.0',\n",
       " '2016_IN_1.0',\n",
       " '2016_KS_2.0',\n",
       " '2016_MD_7.0',\n",
       " '2016_AR_3.0',\n",
       " '2016_MA_7.0',\n",
       " '2016_AZ_3.0',\n",
       " '2016_CA_37.0',\n",
       " '2016_NE_1.0',\n",
       " '2016_TN_2.0',\n",
       " '2016_TX_34.0',\n",
       " '2016_IL_15.0',\n",
       " '2016_WA_10.0',\n",
       " '2016_MA_6.0',\n",
       " '2016_TX_2.0',\n",
       " '2016_CA_6.0',\n",
       " '2016_WA_9.0',\n",
       " '2016_MS_2.0',\n",
       " '2016_IL_3.0',\n",
       " '2016_FL_20.0',\n",
       " '2016_HI_2.0',\n",
       " '2016_NC_3.0',\n",
       " '2016_CA_1.0',\n",
       " '2016_MI_14.0',\n",
       " '2016_TX_29.0',\n",
       " '2016_TX_8.0',\n",
       " '2016_CA_40.0',\n",
       " '2016_NJ_3.0',\n",
       " '2016_PA_18.0',\n",
       " '2016_GA_11.0',\n",
       " '2016_MA_2.0',\n",
       " '2016_KY_4.0',\n",
       " '2016_PA_4.0',\n",
       " '2016_MA_5.0',\n",
       " '2016_CA_34.0',\n",
       " '2016_NE_3.0',\n",
       " '2016_AL_4.0',\n",
       " '2016_TX_16.0',\n",
       " '2016_TX_9.0',\n",
       " '2016_MN_5.0',\n",
       " '2016_CA_30.0',\n",
       " '2016_GA_10.0',\n",
       " '2016_TX_20.0',\n",
       " None,\n",
       " '2016_CA_17.0',\n",
       " '2016_PA_1.0',\n",
       " '2016_AL_1.0',\n",
       " '2016_NM_1.0',\n",
       " '2016_MO_1.0',\n",
       " '2016_OK_2.0',\n",
       " '2016_CA_43.0',\n",
       " '2016_VT_0.0',\n",
       " '2016_MI_5.0',\n",
       " '2016_IL_7.0',\n",
       " '2016_TX_25.0',\n",
       " '2016_TN_9.0',\n",
       " '2016_NJ_12.0',\n",
       " '2016_LA_1.0',\n",
       " '2016_OR_1.0',\n",
       " '2016_AR_1.0',\n",
       " '2016_CA_2.0',\n",
       " '2016_NY_8.0',\n",
       " '2016_MI_9.0',\n",
       " '2016_GA_12.0',\n",
       " '2016_MS_3.0',\n",
       " '2016_AZ_8.0',\n",
       " '2016_AL_7.0',\n",
       " '2016_TX_36.0',\n",
       " '2016_NJ_11.0',\n",
       " '2016_TN_7.0',\n",
       " '2016_NC_5.0',\n",
       " '2016_TX_28.0',\n",
       " '2016_AK_0.0',\n",
       " '2016_CA_22.0',\n",
       " '2016_NY_6.0',\n",
       " '2016_AR_4.0',\n",
       " '2016_WA_2.0',\n",
       " '2016_IL_2.0',\n",
       " '2016_GA_1.0',\n",
       " '2016_IN_6.0',\n",
       " '2016_TX_30.0',\n",
       " '2016_CA_38.0',\n",
       " '2016_GA_3.0',\n",
       " '2016_IL_16.0',\n",
       " '2016_NY_7.0',\n",
       " '2016_MN_6.0',\n",
       " '2016_OR_2.0',\n",
       " '2016_IL_4.0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house18 = df_house18.join(avgsum_donation_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('avgdonation','AVERAGE_DONATION')\n",
    "df_house18 = df_house18.withColumnRenamed('sumdonation','TOTAL_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_big_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_BIG_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(num_out_of_state_donations_18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OUT_OF_STATE_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "df_house18 = df_house18.join(numdonations18, on='CAND_ID', how='left')\n",
    "df_house18 = df_house18.withColumnRenamed('numdonat','NUMBER_OF_DONATIONS')\n",
    "df_house18 = df_house18.drop(col('_c0'))\n",
    "\n",
    "#identification based on existence, so filling na values with 0 where none found\n",
    "df_house18 = df_house18.fillna({'NUMBER_BIG_DONATIONS':0, 'NUMBER_OUT_OF_STATE_DONATIONS':0})\n",
    "\n",
    "#not not all candidates were able to join - filter out those without contribution info\n",
    "df_house18 = df_house18.filter(col('TOTAL_DONATIONS').isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Combine 2016 and 2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house = reduce(DataFrame.unionAll, [df_house16,df_house18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CAND_ID: string (nullable = true)\n",
      " |-- CAND_NAME: string (nullable = true)\n",
      " |-- CAND_PTY_AFFILIATION: string (nullable = true)\n",
      " |-- CAND_ELECTION_YR: integer (nullable = true)\n",
      " |-- CAND_OFFICE_ST: string (nullable = true)\n",
      " |-- CAND_OFFICE: string (nullable = true)\n",
      " |-- CAND_OFFICE_DISTRICT: double (nullable = true)\n",
      " |-- CAND_ICI: string (nullable = true)\n",
      " |-- CAND_STATUS: string (nullable = true)\n",
      " |-- CAND_PCC: string (nullable = true)\n",
      " |-- CAND_CITY: string (nullable = true)\n",
      " |-- CAND_ST: string (nullable = true)\n",
      " |-- CAND_ZIP: double (nullable = true)\n",
      " |-- CAND_VOTES: integer (nullable = true)\n",
      " |-- TOTAL_VOTES: integer (nullable = true)\n",
      " |-- PERCENT_VOTES: double (nullable = true)\n",
      " |-- WINNER: integer (nullable = true)\n",
      " |-- AVERAGE_DONATION: double (nullable = true)\n",
      " |-- TOTAL_DONATIONS: double (nullable = true)\n",
      " |-- NUMBER_BIG_DONATIONS: integer (nullable = false)\n",
      " |-- NUMBER_OUT_OF_STATE_DONATIONS: integer (nullable = false)\n",
      " |-- NUMBER_OF_DONATIONS: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_house.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_house.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEED TO WORK ON THE RELATIVE CALCULATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "training_fraction = [0.8, 0.2]\n",
    "ITERS = 10\n",
    "target = 'WINNER'\n",
    "vars_to_keep = ['TOTAL_DONATIONS','AVERAGE_DONATION','NUMBER_OF_DONATIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_house.select([target]+vars_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|WINNER|count|\n",
      "+------+-----+\n",
      "|     1|  785|\n",
      "|     0|  621|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+------------------+-------------------+\n",
      "|WINNER|TOTAL_DONATIONS|  AVERAGE_DONATION|NUMBER_OF_DONATIONS|\n",
      "+------+---------------+------------------+-------------------+\n",
      "|     0|          600.0|             300.0|                  2|\n",
      "|     0|         6300.0|             630.0|                 10|\n",
      "|     1|       606972.0| 688.1768707482993|                882|\n",
      "|     1|       204101.0|1607.0944881889764|                127|\n",
      "|     1|       142575.0|1071.9924812030076|                133|\n",
      "|     0|        26719.0|460.67241379310343|                 58|\n",
      "|     0|        20450.0| 538.1578947368421|                 38|\n",
      "|     1|       104530.0| 901.1206896551724|                116|\n",
      "|     0|         4200.0|             600.0|                  7|\n",
      "|     1|       154000.0|  649.789029535865|                237|\n",
      "+------+---------------+------------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_model.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Individual Feature, building model and ranking AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FROM ASSIGNMENT 7 ##\n",
    "\n",
    "def compute_univariate_aucs(df, target, training_fraction, iters, seed):\n",
    "\n",
    "    # split the data into train/test using seed\n",
    "    data_train, data_test = df.randomSplit(training_fraction,seed=seed)\n",
    "    \n",
    "    # list of predictor variables\n",
    "    vars = df.columns[1:]\n",
    "    \n",
    "    # results storage\n",
    "    df_auc = pd.DataFrame(index=vars, columns=['weight','auroc'])    \n",
    "\n",
    "    for v in vars:    \n",
    "        print('=== analysis of variable: {}'.format(v))\n",
    "\n",
    "        # create train and test dataframes with columns: target, v\n",
    "        datai_tr = data_train.select(target,v)\n",
    "        datai_te = data_test.select(target,v)\n",
    "\n",
    "        # cast to LabeledPoint\n",
    "        # train\n",
    "        datai_tr_lp = datai_tr \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "        \n",
    "        # test\n",
    "        datai_te_lp = datai_te \\\n",
    "                     .rdd \\\n",
    "                     .map(lambda row: reg.LabeledPoint(row[0], row[1:]))\n",
    "\n",
    "        # train logistic regression, setting iterations, including intercept\n",
    "        LR_Model = LogisticRegressionWithLBFGS.train(datai_tr_lp, iterations=iters, intercept=False)\n",
    "\n",
    "        # from test set, zip labels with predicted labels and cast to float\n",
    "        #p.label    # gives label\n",
    "        #p.features # gives features\n",
    "        \n",
    "        act_pred_test_set = datai_te_lp.map(lambda p: (p.label, LR_Model.predict(p.features))) \\\n",
    "                                            .map(lambda row: (row[0], row[1] * 1.0))\n",
    "        \n",
    "        metrics = BinaryClassificationMetrics(act_pred_test_set)\n",
    "        # metrics.areaUnderROC\n",
    "        \n",
    "        df_auc['weight'].loc[v] = LR_Model.weights  # store the weights\n",
    "        df_auc['auroc'].loc[v] = metrics.areaUnderROC # extract AUROC\n",
    "        print('=== completed analysis of variable: {}'.format(v))\n",
    "        \n",
    "    df_auc.sort_values(by='auroc', ascending=False, inplace=True)\n",
    "    \n",
    "    return df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== analysis of variable: TOTAL_DONATIONS\n",
      "=== completed analysis of variable: TOTAL_DONATIONS\n",
      "=== analysis of variable: AVERAGE_DONATION\n",
      "=== completed analysis of variable: AVERAGE_DONATION\n",
      "=== analysis of variable: NUMBER_OF_DONATIONS\n",
      "=== completed analysis of variable: NUMBER_OF_DONATIONS\n"
     ]
    }
   ],
   "source": [
    "df_output = compute_univariate_aucs(df_model, target, training_fraction, ITERS, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>auroc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL_DONATIONS</th>\n",
       "      <td>[5.095562920049984e-07]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVERAGE_DONATION</th>\n",
       "      <td>[5.146906493825712e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUMBER_OF_DONATIONS</th>\n",
       "      <td>[8.923299131147139e-05]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      weight auroc\n",
       "TOTAL_DONATIONS      [5.095562920049984e-07]     1\n",
       "AVERAGE_DONATION     [5.146906493825712e-05]     1\n",
       "NUMBER_OF_DONATIONS  [8.923299131147139e-05]     1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
